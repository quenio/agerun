Check build logs for hidden issues that might not be caught by the build summary.

**Critical**: This check must pass or CI will fail. The log parser uses precise patterns to extract metrics ([details](../../../kb/build-log-extraction-patterns.md), [syntax](../../../kb/grep-or-syntax-differences.md)). Build checks run in parallel for efficiency ([details](../../../kb/parallel-build-job-integration.md)). CI may fail with network timeouts from deprecated actions ([details](../../../kb/github-actions-deprecated-tool-migration.md)).

## CHECKPOINT WORKFLOW ENFORCEMENT

**CRITICAL**: This command MUST use checkpoint tracking for ALL execution.

### In-Progress Workflow Detection

If a `/check-logs` workflow is already in progress:

```bash
make checkpoint-status CMD=check-logs VERBOSE=--verbose
# Resume: make checkpoint-update CMD=check-logs STEP=N
# Or reset: make checkpoint-cleanup CMD=check-logs && make checkpoint-init CMD=check-logs STEPS='"Run Build" "Standard Checks" "Deep Analysis" "Categorize Errors" "Fix Issues" "Update Whitelist" "Re-check Logs" "Final Validation"'
```

### First-Time Initialization Check

```bash
if [ ! -f /tmp/check-logs-progress.txt ]; then
  echo "‚ö†Ô∏è  Initializing checkpoint tracking..."
  make checkpoint-init CMD=check-logs STEPS='"Run Build" "Standard Checks" "Deep Analysis" "Categorize Errors" "Fix Issues" "Update Whitelist" "Re-check Logs" "Final Validation"'
else
  make checkpoint-status CMD=check-logs
fi
```

## PRECONDITION: Checkpoint Tracking Must Be Initialized

```bash
if [ ! -f /tmp/check-logs-progress.txt ]; then
  echo "‚ùå ERROR: Checkpoint tracking not initialized!"
  exit 1
fi
```

## MANDATORY KB Consultation

Before analysis:
1. Search: `grep "log\|analysis\|build" kb/README.md`
2. Must read:
   - check-logs-deep-analysis-pattern
   - build-log-extraction-patterns
   - ci-network-timeout-diagnosis
3. Apply deep analysis patterns

# Check Logs
## Checkpoint Tracking

This command uses checkpoint tracking to ensure systematic log verification and issue resolution. The process has 8 checkpoints across 4 phases with critical error handling gates.

### Initialize Tracking
```bash
# Start the log checking process
make checkpoint-init CMD=check-logs STEPS='"Run Build" "Standard Checks" "Deep Analysis" "Categorize Errors" "Fix Issues" "Update Whitelist" "Re-check Logs" "Final Validation"'
```

**Expected output:**
```
üìç Starting: check-logs (8 steps)
üìÅ Tracking: /tmp/check-logs-progress.txt
‚Üí Run: make checkpoint-update CMD=check-logs STEP=1
```

### Check Progress
```bash
make checkpoint-status CMD=check-logs
```

**Expected output (example at 50% completion):**
```
üìà command: X/Y steps (Z%)
   [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] Z%
‚Üí Next: make checkpoint-update CMD=command STEP=N
```

## Minimum Requirements

**MANDATORY for successful completion:**
- [ ] Build must complete successfully (check-logs requires fresh build logs)
- [ ] All real errors must be fixed
- [ ] Intentional errors must be whitelisted
- [ ] Final check must pass (CI ready)

**CRITICAL**: Run `make build 2>&1` BEFORE `make check-logs` - check-logs analyzes logs generated by build ([details](../../../kb/build-logs-relationship-principle.md))

Check build logs for hidden issues that might not be caught by the build summary.
### What it does

This command performs a two-phase analysis of build log files:

### Stage 1: Standard Checks
Detects known critical issues including:
- Assertion failures
- Segmentation faults or crashes
- Test failures that might not be properly reported
- Memory errors from sanitizers
- Thread safety issues
- Deep copy support errors
- Method loading warnings
- Unexpected test behaviors (e.g., tests expecting failure that succeed)
- Method evaluation failures
- Missing AST errors

### Stage 2: Deep Analysis (if standard checks pass)
Performs additional thorough analysis to catch edge cases:
- Scans for any ERROR/WARNING patterns that might have been missed
- Verifies test output consistency ([details](../../../kb/systematic-consistency-verification.md))
- Checks for suspicious patterns in test-related output
- Searches for failure indicators (Cannot, Unable to, Failed to)
- Provides detailed counts and examples of any anomalies found

### Stage 1: Initial Check (Steps 1-2)

#### [CHECKPOINT START - STAGE 1]

#### [CHECKPOINT END]

#### Step 1: Run Build

```bash
# Ensure fresh build before checking
echo "Running fresh build..."
if ! make clean build 2>&1; then
  echo "‚ùå Build failed - must fix build errors first"
  exit 1
fi

echo "‚úÖ Build completed successfully"
make checkpoint-update CMD=check-logs STEP=1
```

#### Step 2: Standard Checks

```bash
# Run Stage 1 log analysis
echo "Running standard log checks..."
ERROR_COUNT=0

if make check-logs 2>&1 | tee /tmp/check-logs-output.txt; then
  echo "‚úÖ No errors found in standard checks"
else
  ERROR_COUNT=$(grep -E "ERROR|FAILURE|ASSERT" /tmp/check-logs-output.txt | wc -l || echo "0")
  echo "‚ö†Ô∏è Found $ERROR_COUNT potential issues"
fi

echo "ERROR_COUNT=$ERROR_COUNT" > /tmp/check-logs-stats.txt
make checkpoint-update CMD=check-logs STEP=2
```

#### [BUILD GATE]
```bash
# Verify build is clean before deeper analysis
make checkpoint-gate CMD=check-logs GATE="Build" REQUIRED="1"
```

**Expected gate output:**
```
‚úÖ GATE 'Build' - PASSED
   Verified: Steps 1
```

### Stage 2: Analysis (Steps 3-4)

#### [CHECKPOINT START - STAGE 2]

#### [CHECKPOINT END]

#### Step 3: Deep Analysis

```bash
# Run Stage 2 deep analysis if standard passed
source /tmp/check-logs-stats.txt

if [ $ERROR_COUNT -eq 0 ]; then
  echo "Running deep analysis..."
  python3 scripts/check_logs.py --deep 2>&1 | tee /tmp/deep-analysis.txt
  
  if grep -E "WARNING|suspicious" /tmp/deep-analysis.txt > /dev/null 2>&1; then
    echo "‚ö†Ô∏è Deep analysis found warnings"
  else
    echo "‚úÖ Deep analysis clean"
  fi
else
  echo "Skipping deep analysis - standard checks found issues"
fi

make checkpoint-update CMD=check-logs STEP=3
```

#### Step 4: Categorize Errors

```bash
# Categorize errors found using helper script
source /tmp/check-logs-stats.txt

if [ $ERROR_COUNT -gt 0 ]; then
  # Run categorization and append results to stats file
  ./scripts/categorize-log-errors.sh /tmp/check-logs-output.txt log_whitelist.yaml | tee -a /tmp/check-logs-stats.txt
fi

make checkpoint-update CMD=check-logs STEP=4
```

#### [CRITICAL ERROR GATE]
```bash
# ‚ö†Ô∏è CRITICAL: If errors found, must resolve before proceeding
source /tmp/check-logs-stats.txt
if [ ${ERROR_COUNT:-0} -gt 0 ]; then
  make checkpoint-gate CMD=check-logs GATE="Error Analysis" REQUIRED="3,4"
fi
```

**Expected gate output (when errors found):**
```
========================================
   GATE: Error Analysis
========================================

‚ö†Ô∏è CRITICAL: Errors detected!

Error Summary:
  Total errors: 12
  Real errors to fix: 3
  Intentional errors to whitelist: 9

‚úÖ GATE PASSED: Analysis complete

Proceed to resolution phase.
```

### Stage 3: Resolution (Steps 5-6)

#### [CHECKPOINT START - STAGE 3]

#### [CHECKPOINT END]

#### Step 5: Fix Issues

```bash
# Fix real errors (manual step)
source /tmp/check-logs-stats.txt

if [ ${REAL_ERRORS:-0} -gt 0 ]; then
  echo "‚ö†Ô∏è Manual intervention required!"
  echo "Fix the $REAL_ERRORS real errors identified above."
  echo "After fixing, mark this step complete."
else
  echo "‚úÖ No real errors to fix"
fi

make checkpoint-update CMD=check-logs STEP=5
```

#### Step 6: Update Whitelist

```bash
# Update whitelist for intentional errors
source /tmp/check-logs-stats.txt

if [ ${INTENTIONAL_ERRORS:-0} -gt 0 ]; then
  echo "Updating whitelist for $INTENTIONAL_ERRORS intentional errors..."
  echo "Add the following to log_whitelist.yaml:"
  
  # Show errors needing whitelist
  grep "ERROR\|FAILURE" /tmp/check-logs-output.txt | head -5
  
  echo "\n‚úÖ Whitelist updated"
else
  echo "‚úÖ No whitelist updates needed"
fi

make checkpoint-update CMD=check-logs STEP=6
```

### Stage 4: Verification (Steps 7-8)

#### [CHECKPOINT START - STAGE 4]

#### [CHECKPOINT END]

#### Step 7: Re-check Logs

```bash
# Re-run checks after fixes
echo "Re-checking logs after fixes..."

if make check-logs 2>&1; then
  echo "‚úÖ All log checks now pass!"
  FINAL_STATUS="PASS"
else
  echo "‚ùå Log checks still failing"
  FINAL_STATUS="FAIL"
fi

echo "FINAL_STATUS=$FINAL_STATUS" >> /tmp/check-logs-stats.txt
make checkpoint-update CMD=check-logs STEP=7
```

#### Step 8: Final Validation

```bash
# Final CI readiness check
source /tmp/check-logs-stats.txt

if [ "$FINAL_STATUS" = "PASS" ]; then
  echo "‚úÖ Build is CI-ready!"
  echo "All checks passed, no errors detected."
else
  echo "‚ùå Build is NOT CI-ready"
  echo "Fix remaining issues before pushing to CI."
  exit 1
fi

make checkpoint-update CMD=check-logs STEP=8
```

#### [CHECKPOINT COMPLETE]
```bash
./scripts/complete-checkpoint.sh check-logs
```

**Expected completion output:**
```
========================================
   CHECKPOINT COMPLETION SUMMARY
========================================

üìà check-logs: X/Y steps (Z%)
   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%

‚úÖ Checkpoint workflow complete
```
rm -f /tmp/check-logs-*.txt /tmp/deep-analysis.txt
```

### Usage

```bash
make check-logs
```

**Or with checkpoint tracking:**
```bash
# Initialize and run through checkpoints
make checkpoint-init CMD=check-logs STEPS='...'
# Follow checkpoint steps above
```

## Why it's important:

Even when `make build` shows "SUCCESS", the logs may contain:
- Assertion failures that didn't propagate to the build script
- Warnings or errors that should be addressed
- Tests that are failing silently
- Important diagnostic output

## Recommended workflow:

1. Run `make build` first
2. Always follow up with `make check-logs` to double-check
3. If issues are found, examine the specific log files in `logs/`

## Log file locations:

- `logs/run-tests.log` - Standard test execution
- `logs/sanitize-tests.log` - Tests with AddressSanitizer
- `logs/tsan-tests.log` - Tests with ThreadSanitizer
- `logs/analyze-exec.log` - Static analysis of executable
- `logs/analyze-tests.log` - Static analysis of tests

To view a specific log: `less logs/<logname>.log`
To search all logs: `grep -r 'pattern' logs/`

This check is especially important after the critical build system issue discovered on 2025-07-28 where test failures were not being properly reported ([details](../../../kb/build-system-exit-code-verification.md)).

The log checker uses context-aware filtering to distinguish between intentional test errors and real problems ([details](../../../kb/intentional-test-errors-filtering.md)).

## Troubleshooting

### If check-logs keeps failing:
```bash
# Check specific log files
grep -n "ERROR\|FAILURE" logs/*.log

# Verify whitelist is being applied
python3 scripts/check_logs.py --verbose

# Check for new test errors
diff logs/run-tests.log logs/run-tests.log.previous
```

### Common issues:
1. **New test added**: May introduce intentional errors needing whitelist
2. **Whitelist syntax**: YAML formatting affects matching
3. **Environment differences**: Test names may vary (sanitizer suffixes)
4. **Real failures**: Memory leaks, assertions, segfaults need fixing

### Quick fixes:
```bash
# For intentional errors, add to whitelist:
echo '  - context: "test_name"' >> log_whitelist.yaml
echo '    message: "ERROR: message"' >> log_whitelist.yaml
echo '    comment: "Testing error case"' >> log_whitelist.yaml

# Then verify:
make check-logs
```

## Related Documentation

### Checkpoint Patterns
- [Multi-Step Checkpoint Tracking Pattern](../../../kb/multi-step-checkpoint-tracking-pattern.md)
- [Gate Enforcement Exit Codes Pattern](../../../kb/gate-enforcement-exit-codes-pattern.md)
- [Command Thoroughness Requirements Pattern](../../../kb/command-thoroughness-requirements-pattern.md)

### Log Checking Patterns
- [Build System Exit Code Verification](../../../kb/build-system-exit-code-verification.md)
- [Intentional Test Errors Filtering](../../../kb/intentional-test-errors-filtering.md)
- [Log Format Variation Handling](../../../kb/log-format-variation-handling.md)
- [YAML String Matching Pitfalls](../../../kb/yaml-string-matching-pitfalls.md)
- [Whitelist Simplification Pattern](../../../kb/whitelist-simplification-pattern.md)
- [Systematic Error Whitelist Reduction](../../../kb/systematic-error-whitelist-reduction.md)
- [Uniform Filtering Application](../../../kb/uniform-filtering-application.md)
- [Check-Logs Deep Analysis Pattern](../../../kb/check-logs-deep-analysis-pattern.md)
- [Whitelist vs Pattern Filtering](../../../kb/whitelist-vs-pattern-filtering.md)

### Diagnostic Troubleshooting
- [Shell Configuration Diagnostic Troubleshooting](../../../kb/shell-configuration-diagnostic-troubleshooting.md)
- [Configuration Migration Troubleshooting Strategy](../../../kb/configuration-migration-troubleshooting-strategy.md)

## Managing Intentional Errors

If `make check-logs` reports errors that are intentional (e.g., testing error handling), you should add them to the whitelist:

1. Look at the error output from `check_logs.py` to identify:
   - The test context (shown as "in test: test_name")
   - The error message (without timestamp)

2. Add an entry to `log_whitelist.yaml`:
   ```yaml
   - context: "ar_method_evaluator_tests"  # The test where error occurs
     message: "ERROR: Method evaluation failed"
     comment: "Testing error handling for invalid method"
   ```

3. Key points about the simplified whitelist:
   - `context`: The exact test name or "executable" for non-test contexts
   - `message`: The error/warning message to match (timestamps automatically stripped)
   - `comment`: Optional description of why this is whitelisted
   - No more before/after matching - context + message is sufficient ([details](../../../kb/whitelist-simplification-pattern.md))
   - Consider fixing root causes instead of whitelisting ([details](../../../kb/systematic-error-whitelist-reduction.md))

Example workflow:
```bash
# Run tests and check logs
make build 2>&1
make check-logs

# If intentional errors are found, examine the output:
# logs/run-tests.log:123:ERROR: Expected literal (string or number) (at position 0) (in test: ar_expression_parser_tests)

# Add to log_whitelist.yaml:
ignored_errors:
  - context: "ar_expression_parser_tests"
    message: "ERROR: Expected literal (string or number) (at position 0)"
    comment: "Testing parser error handling for invalid expressions"
```

**Important notes**:
- Test names may vary by environment (e.g., sanitizer tests append suffixes) ([details](../../../kb/log-format-variation-handling.md))
- YAML quote handling can affect matching ([details](../../../kb/yaml-string-matching-pitfalls.md))
- Whitelist is applied uniformly across all checks ([details](../../../kb/uniform-filtering-application.md))

## Related Patterns
- [Evidence-Based Debugging](../../../kb/evidence-based-debugging.md) - Use log output as evidence for debugging
- [Script Debugging Through Isolation](../../../kb/script-debugging-through-isolation.md) - Isolate build failures before whitelisting
- [Cross-Platform Bash Script Patterns](../../../kb/cross-platform-bash-script-patterns.md) - Ensure check-logs works on macOS and Linux